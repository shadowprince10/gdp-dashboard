# -*- coding: utf-8 -*-
# thesis_clustering_code_website.ipynb

# Automatically generated by Colab.

# Original file is located at
#    https://colab.research.google.com/drive/1c30LXmYleWHIX2TID7laGwWzu7dE19_R

"""#### 2440094680 - Belinda"""

# 1. Import Libraries

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
from pathlib import Path
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from mpl_toolkits.mplot3d import Axes3D
import datetime as dt

from functools import reduce

from itertools import product

import statistics as st

from scipy.stats import shapiro, kstest, anderson
from scipy import stats
from scipy.spatial.distance import cdist

from sklearn.decomposition import PCA

from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler, MinMaxScaler, RobustScaler

from sklearn.neighbors import NearestNeighbors
from sklearn.cluster import KMeans, DBSCAN, OPTICS, MeanShift, estimate_bandwidth

from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score

import streamlit

streamlit.set_page_config(
    page_title = "UK Online Retail Customer Dashboard"
)

DATA_FILENAME = Path(__file__).parent/'data/Online Retail.csv'
OnlineRetailDF = pd.read_csv(DATA_FILENAME)
# OnlineRetailDF = pd.read_csv("Online Retail.csv")

streamlit.title("UK-Based Online Retail Customer Dashboard")
streamlit.write("Note: the sliders and the graphics use the standardized Recency, Frequency, and Monetary data.")
streamlit.write("Note: Cluster label -1 of DBSCAN and OPTICS clustering algorithm indicates outliers.")

# OnlineRetailDF.isnull().sum()

OnlineRetailDF.dropna(subset = ["CustomerID"], axis = 0, inplace = True)

# OnlineRetailDF.isnull().sum()

# OnlineRetailDF

# OnlineRetailDF.shape

print("\n\n\n")


print("\n\n\n")

OnlineRetailDF.drop(columns = ["index", "Description"], inplace = True)

zeroPriceData = OnlineRetailDF[OnlineRetailDF["UnitPrice"] == 0]
# zeroPriceData

# zeroPriceData.shape

# OnlineRetailDF[OnlineRetailDF["Quantity"] < 0].Quantity.sort_values()

OnlineRetailDF.drop(labels = zeroPriceData.index, axis = 0, inplace = True) # remove observations containing products with unit price of zero

# OnlineRetailDF.sort_values(by = ["UnitPrice"], ascending = True)

# OnlineRetailDF.sort_values(by = ["InvoiceNo"], ascending = False)

# OnlineRetailDF[OnlineRetailDF.InvoiceNo.str.contains('C')]

# remove observations or records with informations of cancelled products
OnlineRetailDF = OnlineRetailDF[~OnlineRetailDF.InvoiceNo.str.contains('C', na = False)]

# OnlineRetailDF.sort_values(by = ["InvoiceNo"], ascending = False)

# OnlineRetailDF.sort_values(by = ["Quantity"], ascending = True)

# OnlineRetailDF[["Country"]].sort_values(by = ["Country"], ascending = False)

print("\n\n\n")


OnlineRetailDF["InvoiceDate"] = pd.to_datetime(OnlineRetailDF["InvoiceDate"])

OnlineRetailDF.rename(columns = {"InvoiceDate": "InvoiceDateTime"}, inplace = True)

# OnlineRetailDF.columns

# print("Least recent date: ", OnlineRetailDF["InvoiceDateTime"].min())
# print("Most recent/latest date: ", OnlineRetailDF["InvoiceDateTime"].max())

OnlineRetailDF["Year"] = OnlineRetailDF["InvoiceDateTime"].dt.year

OnlineRetailDF["Month"] = OnlineRetailDF["InvoiceDateTime"].dt.month

OnlineRetailDF["InvoiceDate"] = OnlineRetailDF["InvoiceDateTime"].dt.date

OnlineRetailDF["TotalSales"] = round(OnlineRetailDF["Quantity"] * OnlineRetailDF["UnitPrice"], 2)

# OnlineRetailDF

# OnlineRetailDF.describe()

# OnlineRetailDF[OnlineRetailDF["TotalSales"] < 0].TotalSales.sort_values()

OnlineRetailDF.drop(columns = ["UnitPrice"], inplace = True)

# OnlineRetailDF.describe()

# OnlineRetailDF

print("\n\n\n")

# Monetary
# OnlineRetailDF.sort_values(by = ["TotalSales"], ascending = False)

# Monetary grouped by Customer ID
# print(OnlineRetailDF.groupby(by = ["CustomerID"]).count().sort_values(by = ["TotalSales"], ascending = False))

print("\n\n\n\n")

# the latest date is December 10th, 2011 since the last invoice date was December 9th, 2011.
RFM_DF = OnlineRetailDF.groupby("CustomerID").agg({"InvoiceDate": lambda x: (dt.date(2011, 12, 9) - x.max()).days, "InvoiceNo": lambda x: x.nunique(), "TotalSales": lambda x: x.sum()})

RFM_DF["InvoiceDate"] = RFM_DF["InvoiceDate"].astype(int)

# RFM_DF.info()

RFM_DF.rename(columns = {"InvoiceDate": "Recency", "InvoiceNo": "Frequency", "TotalSales": "Monetary"}, inplace = True)

RFM_DF.reset_index(inplace = True)

# RFM_DF

# RFM_DF.columns

# zero_recency_idx = RFM_DF[RFM_DF["Recency"] == 0].index
# zero_recency_idx

# Output:
# Index([  61,   71,  137,  144,  258,  271,  297,  326,  489,  550,  581,  807,
#       1058, 1257, 1521, 1535, 1538, 2176, 2200, 2461, 2542, 2620, 3008, 3088,
#       3136, 3189, 3381, 3413, 3662, 3683, 3712, 3753, 3823, 3954, 4201],
#      dtype='int64')

# invoiceDateDF.loc[zero_recency_idx]

# RFM_DF.sort_values(by = ["Recency"], ascending = True)

# RFM_DF.sort_values(by = ["Frequency"], ascending = False)

X = RFM_DF[["Recency", "Frequency", "Monetary"]]

original_X = X.copy()
# original_X

# original_X.describe()

ss = StandardScaler()

X = ss.fit_transform(X)
# X

RFM_Clusters_DF = RFM_DF.copy() # for samples normalized with Z-score normalization
scaled_X_DF = pd.DataFrame(X, columns = ["Recency", "Frequency", "Monetary"]) # scaled dataset with Recency, Frequency, and Monetary variable
scaled_RFM_Clusters_DF = scaled_X_DF.copy()
# scaled_RFM_Clusters_DF
# RFM_Clusters_DF2 = RFM_DF.copy() # for samples normalized with min-max normalization

# clusters3 = []

# for i in range(2, 11):
#    algo = (KMeans(n_clusters = i, init = "k-means++", n_init = 10, max_iter = 300, random_state = 0, algorithm = "lloyd"))
#    k_means_benchmark = algo.fit(X)
#    clusters3.append(k_means_benchmark.inertia_)

# plt.figure(1, figsize = (20, 10)) # create an empty plot with 1 subplot and given size (20, 10)
# plt.plot(np.arange(2, 11), clusters3, "o")
# plt.plot(np.arange(2, 11), clusters3, "-", alpha = 0.5)
# plt.xlabel("Number of Clusters"), plt.ylabel("Inertia")
# plt.title("Elbow Method for k clusters")
# plt.show()

kmeans = KMeans(init = "k-means++", n_clusters = 5, n_init = 10, max_iter = 300, random_state = 0).fit(X)

kmeans_centroids = kmeans.cluster_centers_
# kmeans_centroids

kmeans_labels = kmeans.labels_
# kmeans_labels

RFM_Clusters_DF["K-Means Cluster"] = kmeans_labels
scaled_RFM_Clusters_DF["K-Means Cluster"] = kmeans_labels

# RFM_Clusters_DF["K-Means Cluster"].value_counts()

print("\n\n\n")

# DBSCAN clustering algorithm with epsilon = 1.7 and minimum_samples = 6 that produces the highest Silhouette Coefficient and lowest Davies-Bouldin Index
dbscan = DBSCAN(eps = 1.7, min_samples = 6).fit(X)
# dbscan

dbscan_labels = dbscan.labels_
# dbscan_labels

n_dbscan_clusters = len(np.unique(dbscan_labels))

n_dbscan_noises = np.sum(np.array(dbscan_labels) == -1, axis = 0)

# print("The estimated number of RFM clusters based on DBSCAN clustering is: %d" % n_dbscan_clusters)

# print("The estimated number of RFM noises based on DBSCAN clustering is: %d" % n_dbscan_noises)

dbscan_clusters = dbscan.fit_predict(X)
# dbscan_clusters

RFM_Clusters_DF["DBSCAN Cluster"] = dbscan_clusters
scaled_RFM_Clusters_DF["DBSCAN Cluster"] = dbscan_clusters

# RFM_Clusters_DF["DBSCAN Cluster"].value_counts()

print("\n\n\n")

optics = OPTICS(min_samples = 110).fit(X)

optics_labels = optics.labels_

optics_clusters = optics.fit_predict(X)

RFM_Clusters_DF["OPTICS Cluster"] = optics_clusters
scaled_RFM_Clusters_DF["OPTICS Cluster"] = optics_clusters

# RFM_Clusters_DF["OPTICS Cluster"].value_counts()

print("\n\n\n")

def find_best_q_with_ss(X):
    quantiles = np.arange(0.1, 1.0, 0.1)
    best_score = -1
    best_quantile = 0

    for quantile in quantiles:
        bw = estimate_bandwidth(X, quantile = quantile, random_state = 0)
        ms = MeanShift(bandwidth = bw, bin_seeding = True).fit(X)
        labels = ms.labels_

        if len(set(labels)) > 1:
            score = silhouette_score(X, labels)

            if score > best_score:
                best_score = score
                best_quantile = quantile

    return best_quantile, best_score

def find_best_q_with_dbi(X):
    quantiles = np.arange(0.1, 1.0, 0.1)
    best_score = 1
    best_quantile = 0

    for quantile in quantiles:
        bw = estimate_bandwidth(X, quantile = quantile, random_state = 0)
        ms = MeanShift(bandwidth = bw, bin_seeding = True).fit(X)
        labels = ms.labels_

        if len(set(labels)) > 1:
            score = davies_bouldin_score(X, labels)

            if score < best_score:
                best_score = score
                best_quantile = quantile

    return best_quantile, best_score

def find_best_q_with_chi(X):
    quantiles = np.arange(0.1, 1.0, 0.1)
    best_score = -1
    best_quantile = 0

    for quantile in quantiles:
        bw = estimate_bandwidth(X, quantile = quantile, random_state = 0)
        ms = MeanShift(bandwidth = bw, bin_seeding = True).fit(X)
        labels = ms.labels_

        if len(set(labels)) > 1:
            score = calinski_harabasz_score(X, labels)

            if score > best_score:
                best_score = score
                best_quantile = quantile

    return best_quantile, best_score

best_q_chi, best_score_chi = find_best_q_with_chi(X)

bw_chi = estimate_bandwidth(X, quantile = best_q_chi, random_state = 0)

ms = MeanShift(bandwidth = bw_chi, bin_seeding = True).fit(X)

ms_centroids = ms.cluster_centers_

ms_labels = ms.labels_

RFM_Clusters_DF["Mean Shift Cluster"] = ms_labels
scaled_RFM_Clusters_DF["Mean Shift Cluster"] = ms_labels

# RFM_Clusters_DF["Mean Shift Cluster"].value_counts()

print("\n\n\n\n")

grouped_km = RFM_Clusters_DF.groupby(["K-Means Cluster"]).mean().round(3).reset_index()
grouped_km["K-Means Cluster"] = grouped_km["K-Means Cluster"].map(str)
# grouped_km[["Recency", "Frequency", "Monetary"]]

kmeans_Cluster0 = RFM_Clusters_DF[RFM_Clusters_DF["K-Means Cluster"] == 0]
kmeans_Cluster1 = RFM_Clusters_DF[RFM_Clusters_DF["K-Means Cluster"] == 1]
kmeans_Cluster2 = RFM_Clusters_DF[RFM_Clusters_DF["K-Means Cluster"] == 2]
kmeans_Cluster3 = RFM_Clusters_DF[RFM_Clusters_DF["K-Means Cluster"] == 3]
kmeans_Cluster4 = RFM_Clusters_DF[RFM_Clusters_DF["K-Means Cluster"] == 4]

print("\n\n\n")

# Outliers
ms_outliers_idx = RFM_Clusters_DF["Mean Shift Cluster"].value_counts()[RFM_Clusters_DF["Mean Shift Cluster"].value_counts() == 1].index

grouped_ms = RFM_Clusters_DF.groupby(["Mean Shift Cluster"]).mean().round(3)
grouped_ms.drop(labels = ms_outliers_idx, axis = 0, inplace = True)
grouped_ms = grouped_ms.reset_index()
grouped_ms["Mean Shift Cluster"] = grouped_ms["Mean Shift Cluster"].map(str)

ms_outliersDF = RFM_Clusters_DF.loc[ms_outliers_idx]

print("\n")

ms_Cluster0 = RFM_Clusters_DF[RFM_Clusters_DF["Mean Shift Cluster"] == 0][["Recency", "Frequency", "Monetary"]]
ms_Cluster1 = RFM_Clusters_DF[RFM_Clusters_DF["Mean Shift Cluster"] == 1][["Recency", "Frequency", "Monetary"]]
ms_Cluster2 = RFM_Clusters_DF[RFM_Clusters_DF["Mean Shift Cluster"] == 2][["Recency", "Frequency", "Monetary"]]
ms_Cluster3 = RFM_Clusters_DF[RFM_Clusters_DF["Mean Shift Cluster"] == 3][["Recency", "Frequency", "Monetary"]]
ms_Cluster4 = RFM_Clusters_DF[RFM_Clusters_DF["Mean Shift Cluster"] == 4][["Recency", "Frequency", "Monetary"]]
ms_Cluster5 = RFM_Clusters_DF[RFM_Clusters_DF["Mean Shift Cluster"] == 5][["Recency", "Frequency", "Monetary"]]
ms_Cluster6 = RFM_Clusters_DF[RFM_Clusters_DF["Mean Shift Cluster"] == 6][["Recency", "Frequency", "Monetary"]]
ms_Cluster7 = RFM_Clusters_DF[RFM_Clusters_DF["Mean Shift Cluster"] == 7][["Recency", "Frequency", "Monetary"]]
ms_Cluster8 = RFM_Clusters_DF[RFM_Clusters_DF["Mean Shift Cluster"] == 8][["Recency", "Frequency", "Monetary"]]
ms_Cluster9 = RFM_Clusters_DF[RFM_Clusters_DF["Mean Shift Cluster"] == 9][["Recency", "Frequency", "Monetary"]]
ms_Cluster10 = RFM_Clusters_DF[RFM_Clusters_DF["Mean Shift Cluster"] == 10][["Recency", "Frequency", "Monetary"]]
ms_Cluster11 = RFM_Clusters_DF[RFM_Clusters_DF["Mean Shift Cluster"] == 11][["Recency", "Frequency", "Monetary"]]
ms_Cluster12 = RFM_Clusters_DF[RFM_Clusters_DF["Mean Shift Cluster"] == 12][["Recency", "Frequency", "Monetary"]]
ms_Cluster13 = RFM_Clusters_DF[RFM_Clusters_DF["Mean Shift Cluster"] == 13][["Recency", "Frequency", "Monetary"]]
ms_Cluster14 = RFM_Clusters_DF[RFM_Clusters_DF["Mean Shift Cluster"] == 14][["Recency", "Frequency", "Monetary"]]
ms_Cluster15 = RFM_Clusters_DF[RFM_Clusters_DF["Mean Shift Cluster"] == 15][["Recency", "Frequency", "Monetary"]]
ms_Cluster16 = RFM_Clusters_DF[RFM_Clusters_DF["Mean Shift Cluster"] == 16][["Recency", "Frequency", "Monetary"]]
ms_Cluster17 = RFM_Clusters_DF[RFM_Clusters_DF["Mean Shift Cluster"] == 17][["Recency", "Frequency", "Monetary"]]
ms_Cluster18 = RFM_Clusters_DF[RFM_Clusters_DF["Mean Shift Cluster"] == 18][["Recency", "Frequency", "Monetary"]]

print("\n\n\n")

dbscan_cluster0 = RFM_Clusters_DF[RFM_Clusters_DF["DBSCAN Cluster"] == 0]

dbscan_outliers = RFM_Clusters_DF[RFM_Clusters_DF["DBSCAN Cluster"] == -1]

optics_cluster0 = RFM_Clusters_DF[RFM_Clusters_DF["OPTICS Cluster"] == 0]

optics_outliers = RFM_Clusters_DF[RFM_Clusters_DF["OPTICS Cluster"] == -1]

# Monetary Mean by K-Means Cluster
mmkc = RFM_Clusters_DF.groupby("K-Means Cluster")["Monetary"].mean()
# K-Means Cluster Labels
mmkc_labels = mmkc.index
# Mean of Monetary Scores
km_monet_avg = mmkc.values

# Total of Monetary by K-Means Cluster
tmkc = RFM_Clusters_DF.groupby("K-Means Cluster")["Monetary"].sum()
# K-Means Cluster Labels
tmkc_labels = tmkc.index
# Mean of Monetary Scores
km_total_monet = tmkc.values

# Frequency Mean by K-Means Cluster
fmkc = RFM_Clusters_DF.groupby("K-Means Cluster")["Frequency"].mean()
# K-Means Cluster Labels
fmkc_labels = fmkc.index
# Mean of Frequency Scores
km_freq_avg = fmkc.values  # Mean Monetary scores

# Total of Frequency by K-Means Cluster
tfkc = RFM_Clusters_DF.groupby("K-Means Cluster")["Frequency"].sum()
# K-Means Cluster Labels
tfkc_labels = tfkc.index
# Mean of Monetary Scores
km_total_freq = tfkc.values

# Recency Mean by K-Means Cluster
rmkc = RFM_Clusters_DF.groupby("K-Means Cluster")["Recency"].mean()
# K-Means Cluster Labels
rmkc_labels = rmkc.index
# Mean of Recency Scores
km_recency_avg = rmkc.values

# Monetary Mean by Mean Shift Cluster
mmmsc = RFM_Clusters_DF.groupby("Mean Shift Cluster")["Monetary"].mean()
# Mean Shift Cluster Labels
mmmsc_labels = mmmsc.index
# Mean of Monetary Scores
ms_monet_avg = mmmsc.values

# Frequency Mean by Mean Shift Cluster
fmmsc = RFM_Clusters_DF.groupby("Mean Shift Cluster")["Frequency"].mean()
# Mean Shift Cluster Labels
fmmsc_labels = fmmsc.index
# Mean of Monetary Scores
ms_freq_avg = fmmsc.values

# Total of Monetary by Mean Shift Cluster
tmmsc = RFM_Clusters_DF.groupby("Mean Shift Cluster")["Monetary"].sum()
# Mean Shift Cluster Labels
tmmsc_labels = tmmsc.index
# Mean of Monetary Scores
total_ms_monet = tmmsc.values

# Total of Frequency by Mean Shift Cluster
tfmsc = RFM_Clusters_DF.groupby("Mean Shift Cluster")["Frequency"].sum()
# Mean Shift Cluster Labels
tfmsc_labels = tfmsc.index
# Mean of Monetary Scores
total_ms_freq = tfmsc.values

# Recency Mean by Mean Shift Cluster
rmmsc = RFM_Clusters_DF.groupby("Mean Shift Cluster")["Recency"].mean()
# Mean Shift Cluster Labels
rmmsc_labels = rmmsc.index
# Mean of Monetary Scores
ms_recency_avg = rmmsc.values

# Monetary Mean by DBSCAN Cluster
mmdc = RFM_Clusters_DF.groupby("DBSCAN Cluster")["Monetary"].mean()
# DBSCAN Cluster Labels
mmdc_labels = mmdc.index
# Mean of DBSCAN Scores
dbscan_monet_avg = mmdc.values

# Total of Monetary by DBSCAN Cluster
tmdc = RFM_Clusters_DF.groupby("DBSCAN Cluster")["Monetary"].sum()
# DBSCAN Cluster Labels
tmdc_labels = tmdc.index
# Mean of DBSCAN Scores
total_dbscan_monet = tmdc.values

# Frequency Mean by DBSCAN Cluster
fmdc = RFM_Clusters_DF.groupby("DBSCAN Cluster")["Frequency"].mean()
# DBSCAN Cluster Labels
fmdc_labels = fmdc.index
# Mean of DBSCAN Scores
dbscan_freq_avg = fmdc.values

# Total of Frequency by DBSCAN Cluster
tfdc = RFM_Clusters_DF.groupby("DBSCAN Cluster")["Frequency"].sum()
# DBSCAN Cluster Labels
tfdc_labels = tfdc.index
# Total of Frequency Scores by DBSCAN Cluster
total_dbscan_freq = tfdc.values

# Recency Mean by DBSCAN Cluster
rmdc = RFM_Clusters_DF.groupby("DBSCAN Cluster")["Recency"].mean()
# DBSCAN Cluster Labels
rmdc_labels = rmdc.index
# Mean of DBSCAN Scores
dbscan_recency_avg = rmdc.values

# Monetary Mean by OPTICS Cluster
mmoc = RFM_Clusters_DF.groupby("OPTICS Cluster")["Monetary"].mean()
# OPTICS Cluster Labels
mmoc_labels = mmoc.index
# Mean of OPTICS Scores
optics_monet_avg = mmoc.values

# Total of Monetary by OPTICS Cluster
tmoc = RFM_Clusters_DF.groupby("OPTICS Cluster")["Monetary"].sum()
# OPTICS Cluster Labels
tmoc_labels = tmoc.index
# Total of Monetary Scores by OPTICS Cluster
total_optics_monet = tmoc.values

# Frequency Mean by OPTICS Cluster
fmoc = RFM_Clusters_DF.groupby("OPTICS Cluster")["Frequency"].mean()
# OPTICS Cluster Labels
fmoc_labels = fmoc.index
# Mean of OPTICS Scores
optics_freq_avg = fmoc.values

# Total of Frequency by OPTICS Cluster
tfoc = RFM_Clusters_DF.groupby("OPTICS Cluster")["Frequency"].sum()
# OPTICS Cluster Labels
tfoc_labels = tfoc.index
# Total of Frequency Scores by OPTICS Cluster
total_optics_freq = tfoc.values

# Recency Mean by OPTICS Cluster
rmoc = RFM_Clusters_DF.groupby("OPTICS Cluster")["Recency"].mean()
# OPTICS Cluster Labels
rmoc_labels = rmoc.index
# Mean of OPTICS Scores
optics_recency_avg = rmoc.values

streamlit.divider()

streamlit.header("K-Means Customer Segments", divider = "gray")

from_first_kmeans_cluster, to_last_kmeans_cluster = streamlit.slider(
    "Which K-Means Cluster are you interested in?",
    min_value = scaled_RFM_Clusters_DF["K-Means Cluster"].min(),
    max_value = scaled_RFM_Clusters_DF["K-Means Cluster"].max(),
    value = [scaled_RFM_Clusters_DF["K-Means Cluster"].min(), scaled_RFM_Clusters_DF["K-Means Cluster"].max()],
    key = "kmeans_cluster_label_slider"
    )

filtered_kmeans_cluster_df = scaled_RFM_Clusters_DF[(scaled_RFM_Clusters_DF["K-Means Cluster"] <= to_last_kmeans_cluster) & (from_first_kmeans_cluster <= scaled_RFM_Clusters_DF["K-Means Cluster"])]

scaled_recency_range1 = streamlit.slider(
        "Which standardized value of Recency in days since December 9th, 2011 as the last purchase date are you interested in?",
        min_value = float(filtered_kmeans_cluster_df["Recency"].min()),
        max_value = float(filtered_kmeans_cluster_df["Recency"].max()),
        value = (float(filtered_kmeans_cluster_df["Recency"].min()), float(filtered_kmeans_cluster_df["Recency"].max())), 
        key = "kmeans_recency_slider"
    )

scaled_frequency_range1 = streamlit.slider(
        "Which standardized value of Frequency in times of purchase are you interested in?",
        min_value = float(filtered_kmeans_cluster_df["Frequency"].min()),
        max_value = float(filtered_kmeans_cluster_df["Frequency"].max()),
        value = (float(filtered_kmeans_cluster_df["Frequency"].min()), float(filtered_kmeans_cluster_df["Frequency"].max())), 
        key = "kmeans_freq_slider"
    )

scaled_monetary_range1 = streamlit.slider(
        "Which standardized value of Monetary in sterling are you interested in?",
        min_value = float(filtered_kmeans_cluster_df["Monetary"].min()),
        max_value = float(filtered_kmeans_cluster_df["Monetary"].max()),
        value = (float(filtered_kmeans_cluster_df["Monetary"].min()), float(filtered_kmeans_cluster_df["Monetary"].max())), 
        key = "kmeans_monet_slider"
    )

# Apply filters dynamically
filtered_df1 = filtered_kmeans_cluster_df.copy()

filtered_df1 = filtered_df1[
        (filtered_df1["Recency"] >= scaled_recency_range1[0]) &
        (filtered_df1["Recency"] <= scaled_recency_range1[1])
    ]

filtered_df1 = filtered_df1[
        (filtered_df1["Frequency"] >= scaled_frequency_range1[0]) &
        (filtered_df1["Frequency"] <= scaled_frequency_range1[1])
    ]

filtered_df1 = filtered_df1[
        (filtered_df1["Monetary"] >= scaled_monetary_range1[0]) &
        (filtered_df1["Monetary"] <= scaled_monetary_range1[1])
    ]

streamlit.subheader("Average of Recency, Frequency, and Monetary Values of the K-Means Cluster(s)")

# Create layout with 3 columns
col1, col2, col3 = streamlit.columns(3)

with col1:
    streamlit.metric("Average of Recency", filtered_df1["Recency"].mean())

with col2:
    streamlit.metric("Average of Frequency", filtered_df1["Frequency"].mean())

with col3:
    streamlit.metric("Average of Monetary", filtered_df1["Monetary"].mean())

kmeans_fig3d_st = px.scatter_3d(filtered_df1, x = "Recency", y = "Frequency", z = "Monetary", color = filtered_df1["K-Means Cluster"],
                           title = "3D K-Means Clusters Visualization", size_max = 30, width = 1000, height = 680, opacity = 1.0)

# kmeans_fig3d_st.show()

streamlit.plotly_chart(kmeans_fig3d_st, use_container_width = True)

# create layout with 2 columns
col4, col5 = streamlit.columns(2)

with col4:
    # Monetary Mean by K-Means Cluster Pie Chart
    streamlit.write("Pie Chart of Contribution to Monetary Mean by K-Means Cluster")
    # Create a pie chart using Plotly
    kmeans_monet_mean_pie = go.Figure(data = [go.Pie(
        labels = [f'Cluster {c}' for c in mmkc_labels],
        values = km_monet_avg,
        textinfo = 'percent+label',
        textposition = 'inside',
        hoverinfo = 'label+percent+value',
        hole = 0.4,
        marker = dict(line = dict(color = 'white', width = 3))
    )])

    # Update layout to add title
    kmeans_monet_mean_pie.update_layout(
        legend_title_text = "K-Means cluster label",
        legend_font_size = 10,
        legend = dict(orientation = "h", yanchor = "bottom", y = -0.3, xanchor = "center", x = 0.5)
    )

    # Display the pie chart in Streamlit
    streamlit.plotly_chart(kmeans_monet_mean_pie)

with col5:
    # Monetary Mean by K-Means Cluster Pie Chart
    streamlit.write("Pie Chart of Contribution to Frequency Mean by K-Means Cluster")
    # Create a pie chart using Plotly
    kmeans_freq_mean_pie = go.Figure(data = [go.Pie(
        labels = [f'Cluster {c}' for c in fmkc_labels],
        values = km_freq_avg,
        textinfo = 'percent+label',
        textposition = 'inside',
        hoverinfo = 'label+percent+value',
        hole = 0.4,
        marker = dict(line = dict(color = 'white', width = 3))
    )])

    # Update layout to add title
    kmeans_freq_mean_pie.update_layout(
        legend_title_text = "K-Means cluster label",
        legend_font_size = 10,
        legend = dict(orientation = "h", yanchor = "bottom", y = -0.3, xanchor = "center", x = 0.5)
    )

    # Display the pie chart in Streamlit
    streamlit.plotly_chart(kmeans_freq_mean_pie)

# create layout with 2 columns
col6, col7 = streamlit.columns(2)

with col6:
    # Total Monetary by K-Means Cluster Pie Chart
    streamlit.write("Pie Chart of Contribution to Total Monetary by K-Means Cluster")
    # Create a pie chart using Plotly
    kmeans_tot_monet_pie = go.Figure(data = [go.Pie(
        labels = [f'Cluster {c}' for c in tmkc_labels],
        values = km_total_monet,
        textinfo = 'percent+label',
        textposition = 'inside',
        hoverinfo = 'label+percent+value',
        hole = 0.4,
        marker = dict(line = dict(color = 'white', width = 3))
    )])

    # Update layout to add title
    kmeans_tot_monet_pie.update_layout(
        legend_title_text = "K-Means cluster label",
        legend_font_size = 10,
        legend = dict(orientation = "h", yanchor = "bottom", y = -0.3, xanchor = "center", x = 0.5)
    )

    # Display the pie chart in Streamlit
    streamlit.plotly_chart(kmeans_tot_monet_pie)

with col7:
    # Monetary Mean by K-Means Cluster Pie Chart
    streamlit.write("Pie Chart of Contribution to Total Frequency by K-Means Cluster")
    # Create a pie chart using Plotly
    kmeans_tot_freq_pie = go.Figure(data = [go.Pie(
        labels = [f'Cluster {c}' for c in tfkc_labels],
        values = km_total_freq,
        textinfo = 'percent+label',
        textposition = 'inside',
        hoverinfo = 'label+percent+value',
        hole = 0.4,
        marker = dict(line = dict(color = 'white', width = 3))
    )])

    # Update layout to add title
    kmeans_tot_freq_pie.update_layout(
        legend_title_text = "K-Means cluster label",
        legend_font_size = 10,
        legend = dict(orientation = "h", yanchor = "bottom", y = -0.3, xanchor = "center", x = 0.5)
    )

    # Display the pie chart in Streamlit
    streamlit.plotly_chart(kmeans_tot_freq_pie)

# if filter_recency:
#     filtered_df = filtered_df[
#         (filtered_df["Recency"] >= recency_range[0]) &
#         (filtered_df["Recency"] <= recency_range[1])
#     ]

# if filter_frequency:
#     filtered_df = filtered_df[
#         (filtered_df["Frequency"] >= frequency_range[0]) &
#         (filtered_df["Frequency"] <= frequency_range[1])
#     ]

# if filter_monetary:
#     filtered_df = filtered_df[
#         (filtered_df["Monetary"] >= monetary_range[0]) &
#         (filtered_df["Monetary"] <= monetary_range[1])
#     ]

# filtered_kmeans_cluster_df = RFM_Clusters_DF[(RFM_Clusters_DF["K-Means Cluster"] <= to_last_kmeans_cluster) & (from_first_kmeans_cluster <= RFM_Clusters_DF["K-Means Cluster"])]

# # Checkbox for Recency
# filter_recency = streamlit.checkbox("Filter by Recency")
# if filter_recency:
#     recency_range = streamlit.slider(
#         "Which value of Recency in days since the last purchase date are you interested in?",
#         min_value = float(filtered_kmeans_cluster_df["Recency"].min()),
#         max_value = float(filtered_kmeans_cluster_df["Recency"].max()),
#         value = (float(filtered_kmeans_cluster_df["Recency"].min()), float(filtered_kmeans_cluster_df["Recency"].max()))
#     )

# # Checkbox for Frequency
# filter_frequency = streamlit.checkbox("Filter by Frequency")
# if filter_frequency:
#     frequency_range = streamlit.slider(
#         "Which value of frequency in times of purchase are you interested in?",
#         min_value = float(filtered_kmeans_cluster_df["Frequency"].min()),
#         max_value = float(filtered_kmeans_cluster_df["Frequency"].max()),
#         value = (float(filtered_kmeans_cluster_df["Frequency"].min()), float(filtered_kmeans_cluster_df["Frequency"].max()))
#     )

# # Checkbox for Monetary
# filter_monetary = streamlit.checkbox("Filter by Monetary")
# if filter_monetary:
#     monetary_range = streamlit.slider(
#         "Which value of monetary in sterling are you interested in?",
#         min_value = float(filtered_kmeans_cluster_df["Monetary"].min()),
#         max_value = float(filtered_kmeans_cluster_df["Monetary"].max()),
#         value = (float(filtered_kmeans_cluster_df["Monetary"].min()), float(filtered_kmeans_cluster_df["Monetary"].max()))
#     )

# # Apply filters dynamically
# filtered_df = RFM_Clusters_DF.copy()

# if filter_recency:
#     filtered_df = filtered_df[
#         (filtered_df["Recency"] >= recency_range[0]) &
#         (filtered_df["Recency"] <= recency_range[1])
#     ]

# if filter_frequency:
#     filtered_df = filtered_df[
#         (filtered_df["Frequency"] >= frequency_range[0]) &
#         (filtered_df["Frequency"] <= frequency_range[1])
#     ]

# if filter_monetary:
#     filtered_df = filtered_df[
#         (filtered_df["Monetary"] >= monetary_range[0]) &
#         (filtered_df["Monetary"] <= monetary_range[1])
#     ]

# # Display the totals side by side
# streamlit.subheader("Total Recency, Frequency, and Monetary Values of the K-Means Cluster(s)")

# # Create columns
# col1, col2, col3 = streamlit.columns(3)

# with col1:
#     streamlit.metric("Total Recency", f"{filtered_df['Recency'].sum()}")

# with col2:
#     streamlit.metric("Total Frequency", f"{filtered_df['Frequency'].sum()}")

# with col3:
#     streamlit.metric("Total Monetary", f"{filtered_df['Monetary'].sum():.3f}")

# kmeans_fig3d_st = px.scatter_3d(X, x = 0, y = 1, z = 2, color = filtered_kmeans_cluster_df["K-Means Cluster"], labels = {"0": "Recency", "1": "Frequency", "2": "Monetary"},
#                            title = "3D K-Means Clusters Visualization", size_max = 30, width = 1000, height = 680, opacity = 1.0)

# # kmeans_fig3d_st.show()

# streamlit.plotly_chart(kmeans_fig3d_st, use_container_width = True)
streamlit.divider()
streamlit.header("DBSCAN Customer Segments", divider = "gray")

from_first_dbscan_cluster, to_last_dbscan_cluster = streamlit.slider(
    "Which DBSCAN Cluster are you interested in?",
    min_value = scaled_RFM_Clusters_DF["DBSCAN Cluster"].min(),
    max_value = scaled_RFM_Clusters_DF["DBSCAN Cluster"].max(),
    value = [scaled_RFM_Clusters_DF["DBSCAN Cluster"].min(), scaled_RFM_Clusters_DF["DBSCAN Cluster"].max()],
    key = "dbscan_cluster_label_slider"
    )

filtered_dbscan_cluster_df = scaled_RFM_Clusters_DF[(scaled_RFM_Clusters_DF["DBSCAN Cluster"] <= to_last_dbscan_cluster) & (from_first_dbscan_cluster <= scaled_RFM_Clusters_DF["DBSCAN Cluster"])]

# Checkbox for Recency
# filter_recency = streamlit.checkbox("Filter by Recency")
# if filter_recency:
scaled_recency_range2 = streamlit.slider(
    "Which standardized value of Recency in days since December 9th, 2011 as the last purchase date are you interested in?",
    min_value = float(filtered_dbscan_cluster_df["Recency"].min()),
    max_value = float(filtered_dbscan_cluster_df["Recency"].max()),
    value = (float(filtered_dbscan_cluster_df["Recency"].min()), float(filtered_dbscan_cluster_df["Recency"].max())), 
    key = "dbscan_recency_slider"
)

# Checkbox for Frequency
# filter_frequency = streamlit.checkbox("Filter by Frequency")
# if filter_frequency:
scaled_frequency_range2 = streamlit.slider(
    "Which standardized value of Frequency in times of purchase are you interested in?",
    min_value = float(filtered_dbscan_cluster_df["Frequency"].min()),
    max_value = float(filtered_dbscan_cluster_df["Frequency"].max()),
    value = (float(filtered_dbscan_cluster_df["Frequency"].min()), float(filtered_dbscan_cluster_df["Frequency"].max())), 
    key = "dbscan_freq_slider"
)

# Checkbox for Monetary
# filter_monetary = streamlit.checkbox("Filter by Monetary")
# if filter_monetary:
scaled_monetary_range2 = streamlit.slider(
    "Which standardized value of Monetary in sterling are you interested in?",
    min_value = float(filtered_dbscan_cluster_df["Monetary"].min()),
    max_value = float(filtered_dbscan_cluster_df["Monetary"].max()),
    value = (float(filtered_dbscan_cluster_df["Monetary"].min()), float(filtered_dbscan_cluster_df["Monetary"].max())), 
    key = "dbscan_monet_slider"
)

# Apply filters dynamically
filtered_df2 = filtered_dbscan_cluster_df.copy()

# if filter_recency:
filtered_df2 = filtered_df2[
    (filtered_df2["Recency"] >= scaled_recency_range2[0]) &
    (filtered_df2["Recency"] <= scaled_recency_range2[1])
]

# if filter_frequency:
filtered_df2 = filtered_df2[
    (filtered_df2["Frequency"] >= scaled_frequency_range2[0]) &
    (filtered_df2["Frequency"] <= scaled_frequency_range2[1])
]

# if filter_monetary:
filtered_df2 = filtered_df2[
    (filtered_df2["Monetary"] >= scaled_monetary_range2[0]) &
    (filtered_df2["Monetary"] <= scaled_monetary_range2[1])
]

# Display the totals side by side
streamlit.subheader("Average of Recency, Frequency, and Monetary Values of the DBSCAN Cluster and/or Outliers")

# Create columns
col1, col2, col3 = streamlit.columns(3)

with col1:
    streamlit.metric("Average of Recency", filtered_df2["Recency"].mean())

with col2:
    streamlit.metric("Average of Frequency", filtered_df2["Frequency"].mean())

with col3:
    streamlit.metric("Average of Monetary", filtered_df2["Monetary"].mean())

dbscan_fig3d_st = px.scatter_3d(filtered_df2, x = "Recency", y = "Frequency", z = "Monetary", color = filtered_df2["DBSCAN Cluster"], 
                           title = "3D DBSCAN Clusters Visualization", size_max = 30, width = 1000, height = 680, opacity = 1.0)

# dbscan_fig3d_st.show()

streamlit.plotly_chart(dbscan_fig3d_st, use_container_width = True)

# create layout with 2 columns
col8, col9 = streamlit.columns(2)

with col8:
    # Monetary Mean by K-Means Cluster Pie Chart
    streamlit.write("Pie Chart of Contribution to Monetary Mean by DBSCAN Cluster & Outliers")
    # Create a pie chart using Plotly
    dbscan_monet_mean_pie = go.Figure(data = [go.Pie(
        labels = [f'Cluster {c}' if c != -1 else "Outliers" for c in mmdc_labels],
        values = dbscan_monet_avg,
        textinfo = 'label+percent',
        textposition = 'inside',
        hoverinfo = 'label+percent+value',
        hole = 0.4,
        marker = dict(line = dict(color = 'white', width = 3))
    )])

    # Update layout to add title
    dbscan_monet_mean_pie.update_layout(
        legend_title_text = "DBSCAN cluster label",
        legend_font_size = 10,
        legend = dict(orientation = "h", yanchor = "bottom", y = -0.3, xanchor = "center", x = 0.5)
    )

    # Display the pie chart in Streamlit
    streamlit.plotly_chart(dbscan_monet_mean_pie)

with col9:
    # Monetary Mean by K-Means Cluster Pie Chart
    streamlit.write("Pie Chart of Contribution to Frequency Mean by DBSCAN Cluster & Outliers")
    # Create a pie chart using Plotly
    dbscan_freq_mean_pie = go.Figure(data = [go.Pie(
        labels = [f'Cluster {c}' if c != -1 else "Outliers" for c in fmdc_labels],
        values = dbscan_freq_avg,
        textinfo = 'percent+label',
        textposition = 'inside',
        hoverinfo = 'label+percent+value',
        hole = 0.4,
        marker = dict(line = dict(color = 'white', width = 3))
    )])

    # Update layout to add title
    dbscan_freq_mean_pie.update_layout(
        legend_title_text = "DBSCAN cluster label",
        legend_font_size = 10,
        legend = dict(orientation = "h", yanchor = "bottom", y = -0.3, xanchor = "center", x = 0.5)
    )

    # Display the pie chart in Streamlit
    streamlit.plotly_chart(dbscan_freq_mean_pie)

# create layout with 2 columns
col10, col11 = streamlit.columns(2)

with col10:
    # Monetary Mean by K-Means Cluster Pie Chart
    streamlit.write("Pie Chart of Contribution to Total Monetary by DBSCAN Cluster & Outliers")
    # Create a pie chart using Plotly
    dbscan_tot_monet_pie = go.Figure(data = [go.Pie(
        labels = [f'Cluster {c}' if c != -1 else "Outliers" for c in tmdc_labels],
        values = total_dbscan_monet,
        textinfo = 'percent+label',
        textposition = 'inside',
        hoverinfo = 'label+percent+value',
        hole = 0.4,
        marker = dict(line = dict(color = 'white', width = 3))
    )])

    # Update layout to add title
    dbscan_tot_monet_pie.update_layout(
        legend_title_text = "DBSCAN cluster label",
        legend_font_size = 10,
        legend = dict(orientation = "h", yanchor = "bottom", y = -0.3, xanchor = "center", x = 0.5)
    )

    # Display the pie chart in Streamlit
    streamlit.plotly_chart(dbscan_tot_monet_pie)

with col11:
    # Monetary Mean by K-Means Cluster Pie Chart
    streamlit.write("Pie Chart of Contribution to Total Frequency by DBSCAN Cluster & Outliers")
    # Create a pie chart using Plotly
    dbscan_tot_freq_pie = go.Figure(data = [go.Pie(
        labels = [f'Cluster {c}' if c != -1 else "Outliers" for c in tfdc_labels],
        values = total_dbscan_freq,
        textinfo = 'percent+label',
        textposition = 'inside',
        hoverinfo = 'label+percent+value',
        hole = 0.4,
        marker = dict(line = dict(color = 'white', width = 3))
    )])

    # Update layout to add title
    dbscan_tot_freq_pie.update_layout(
        legend_title_text = "DBSCAN cluster label",
        legend_font_size = 10,
        legend = dict(orientation = "h", yanchor = "bottom", y = -0.3, xanchor = "center", x = 0.5)
    )

    # Display the pie chart in Streamlit
    streamlit.plotly_chart(dbscan_tot_freq_pie)

streamlit.divider()
streamlit.header("OPTICS Customer Segments", divider = "gray")

from_first_optics_cluster, to_last_optics_cluster = streamlit.slider(
    "Which OPTICS Cluster are you interested in?",
    min_value = scaled_RFM_Clusters_DF["OPTICS Cluster"].min(),
    max_value = scaled_RFM_Clusters_DF["OPTICS Cluster"].max(),
    value = [scaled_RFM_Clusters_DF["OPTICS Cluster"].min(), scaled_RFM_Clusters_DF["OPTICS Cluster"].max()],
    key = "optics_cluster_label_slider"
    )

filtered_optics_cluster_df = scaled_RFM_Clusters_DF[(scaled_RFM_Clusters_DF["OPTICS Cluster"] <= to_last_optics_cluster) & (from_first_optics_cluster <= scaled_RFM_Clusters_DF["OPTICS Cluster"])]

# Checkbox for Recency
# filter_recency = streamlit.checkbox("Filter by Recency")
# if filter_recency:
scaled_recency_range3 = streamlit.slider(
    "Which standardized value of Recency in days since December 9th, 2011 as the last purchase date are you interested in?",
    min_value = float(filtered_optics_cluster_df["Recency"].min()),
    max_value = float(filtered_optics_cluster_df["Recency"].max()),
    value = (float(filtered_optics_cluster_df["Recency"].min()), float(filtered_optics_cluster_df["Recency"].max())), 
    key = "optics_recency_slider"
)

# Checkbox for Frequency
# filter_frequency = streamlit.checkbox("Filter by Frequency")
# if filter_frequency:
scaled_frequency_range3 = streamlit.slider(
    "Which standardized value of Frequency in times of purchase are you interested in?",
    min_value = float(filtered_optics_cluster_df["Frequency"].min()),
    max_value = float(filtered_optics_cluster_df["Frequency"].max()),
    value = (float(filtered_optics_cluster_df["Frequency"].min()), float(filtered_optics_cluster_df["Frequency"].max())), 
    key = "optics_freq_slider"
)

# Checkbox for Monetary
# filter_monetary = streamlit.checkbox("Filter by Monetary")
# if filter_monetary:
scaled_monetary_range3 = streamlit.slider(
    "Which standardized value of Monetary in sterling are you interested in?",
    min_value = float(filtered_optics_cluster_df["Monetary"].min()),
    max_value = float(filtered_optics_cluster_df["Monetary"].max()),
    value = (float(filtered_optics_cluster_df["Monetary"].min()), float(filtered_optics_cluster_df["Monetary"].max())), 
    key = "optics_monet_slider"
)

# Apply filters dynamically
filtered_df3 = filtered_optics_cluster_df.copy()

# if filter_recency:
filtered_df3 = filtered_df3[
    (filtered_df3["Recency"] >= scaled_recency_range3[0]) &
    (filtered_df3["Recency"] <= scaled_recency_range3[1])
]

# if filter_frequency:
filtered_df3 = filtered_df3[
    (filtered_df3["Frequency"] >= scaled_frequency_range3[0]) &
    (filtered_df3["Frequency"] <= scaled_frequency_range3[1])
]

# if filter_monetary:
filtered_df3 = filtered_df3[
    (filtered_df3["Monetary"] >= scaled_monetary_range3[0]) &
    (filtered_df3["Monetary"] <= scaled_monetary_range3[1])
]

# Display the totals side by side
streamlit.subheader("Average of Recency, Frequency, and Monetary Values of the OPTICS Cluster and/or Outliers")

# Create columns
col1, col2, col3 = streamlit.columns(3)

with col1:
    streamlit.metric("Average of Recency", filtered_df3["Recency"].mean())

with col2:
    streamlit.metric("Average of Frequency", filtered_df3["Frequency"].mean())

with col3:
    streamlit.metric("Average of Monetary", filtered_df3["Monetary"].mean())

optics_fig3d_st = px.scatter_3d(filtered_df3, x = "Recency", y = "Frequency", z = "Monetary", color = filtered_df3["OPTICS Cluster"], 
                           title = "3D OPTICS Clusters Visualization", size_max = 30, width = 1000, height = 680, opacity = 1.0)

# optics_fig3d_st.show()

streamlit.plotly_chart(optics_fig3d_st, use_container_width = True)

# create layout with 2 columns
col12, col13 = streamlit.columns(2)

with col12:
    # Monetary Mean by K-Means Cluster Pie Chart
    streamlit.write("Pie Chart of Contribution to Monetary Mean by OPTICS Cluster & Outliers")
    # Create a pie chart using Plotly
    optics_monet_mean_pie = go.Figure(data = [go.Pie(
        labels = [f'Cluster {c}' if c != -1 else "Outliers" for c in mmoc_labels],
        values = optics_monet_avg,
        textinfo = 'percent+label',
        textposition = 'inside',
        hoverinfo = 'label+percent+value',
        hole = 0.4,
        marker = dict(line = dict(color = 'white', width = 3))
    )])

    # Update layout to add title
    optics_monet_mean_pie.update_layout(
        legend_title_text = "OPTICS cluster label",
        legend_font_size = 10,
        legend = dict(orientation = "h", yanchor = "bottom", y = -0.3, xanchor = "center", x = 0.5)
    )

    # Display the pie chart in Streamlit
    streamlit.plotly_chart(optics_monet_mean_pie)

with col13:
    # Monetary Mean by K-Means Cluster Pie Chart
    streamlit.write("Pie Chart of Contribution to Frequency Mean by OPTICS Cluster & Outliers")
    # Create a pie chart using Plotly
    optics_freq_mean_pie = go.Figure(data = [go.Pie(
        labels = [f'Cluster {c}' if c != -1 else "Outliers" for c in fmoc_labels],
        values = optics_freq_avg,
        textinfo = 'percent+label',
        textposition = 'inside',
        hoverinfo = 'label+percent+value',
        hole = 0.4,
        marker = dict(line = dict(color = 'white', width = 3))
    )])

    # Update layout to add title
    optics_freq_mean_pie.update_layout(
        legend_title_text = "OPTICS cluster label",
        legend_font_size = 10,
        legend = dict(orientation = "h", yanchor = "bottom", y = -0.3, xanchor = "center", x = 0.5)
    )

    # Display the pie chart in Streamlit
    streamlit.plotly_chart(optics_freq_mean_pie)

# create layout with 2 columns
col14, col15 = streamlit.columns(2)

with col14:
    # Monetary Mean by K-Means Cluster Pie Chart
    streamlit.write("Pie Chart of Contribution to Total Monetary by OPTICS Cluster & Outliers")
    # Create a pie chart using Plotly
    optics_tot_monet_pie = go.Figure(data = [go.Pie(
        labels = [f'Cluster {c}' if c != -1 else "Outliers" for c in tmoc_labels],
        values = total_optics_monet,
        textinfo = 'percent+label',
        textposition = 'inside',
        hoverinfo = 'label+percent+value',
        hole = 0.4,
        marker = dict(line = dict(color = 'white', width = 3))
    )])

    # Update layout to add title
    optics_tot_monet_pie.update_layout(
        legend_title_text = "OPTICS cluster label",
        legend_font_size = 10,
        legend = dict(orientation = "h", yanchor = "bottom", y = -0.3, xanchor = "center", x = 0.5)
    )

    # Display the pie chart in Streamlit
    streamlit.plotly_chart(optics_tot_monet_pie)

with col15:
    # Monetary Mean by K-Means Cluster Pie Chart
    streamlit.write("Pie Chart of Contribution to Total Frequency by OPTICS Cluster & Outliers")
    # Create a pie chart using Plotly
    optics_tot_freq_pie = go.Figure(data = [go.Pie(
        labels = [f'Cluster {c}' if c != -1 else "Outliers" for c in tfoc_labels],
        values = total_optics_freq,
        textinfo = 'percent+label',
        textposition = 'inside',
        hoverinfo = 'label+percent+value',
        hole = 0.4,
        marker = dict(line = dict(color = 'white', width = 3))
    )])

    # Update layout to add title
    optics_tot_freq_pie.update_layout(
        legend_title_text = "OPTICS cluster label",
        legend_font_size = 10,
        legend = dict(orientation = "h", yanchor = "bottom", y = -0.3, xanchor = "center", x = 0.5)
    )

    # Display the pie chart in Streamlit
    streamlit.plotly_chart(optics_tot_freq_pie)

streamlit.divider()
streamlit.header("Mean Shift Customer Segments", divider = "gray")

from_first_ms_cluster, to_last_ms_cluster = streamlit.slider(
    "Which Mean Shift Cluster are you interested in?",
    min_value = scaled_RFM_Clusters_DF["Mean Shift Cluster"].min(),
    max_value = scaled_RFM_Clusters_DF["Mean Shift Cluster"].max(),
    value = [scaled_RFM_Clusters_DF["Mean Shift Cluster"].min(), scaled_RFM_Clusters_DF["Mean Shift Cluster"].max()],
    key = "mean_shift_cluster_label_slider"
    )

filtered_ms_cluster_df = scaled_RFM_Clusters_DF[(scaled_RFM_Clusters_DF["Mean Shift Cluster"] <= to_last_ms_cluster) & (from_first_ms_cluster <= scaled_RFM_Clusters_DF["Mean Shift Cluster"])]

# Checkbox for Recency
# filter_recency = streamlit.checkbox("Filter by Recency")
# if filter_recency:
scaled_recency_range4 = streamlit.slider(
    "Which standardized value of Recency in days since December 9th, 2011 as the last purchase date are you interested in?",
    min_value = float(filtered_ms_cluster_df["Recency"].min()),
    max_value = float(filtered_ms_cluster_df["Recency"].max()),
    value = (float(filtered_ms_cluster_df["Recency"].min()), float(filtered_ms_cluster_df["Recency"].max())), 
    key = "ms_recency_slider"
)

# Checkbox for Frequency
# filter_frequency = streamlit.checkbox("Filter by Frequency")
# if filter_frequency:
scaled_frequency_range4 = streamlit.slider(
    "Which standardized value of Frequency in times of purchase are you interested in?",
    min_value = float(filtered_ms_cluster_df["Frequency"].min()),
    max_value = float(filtered_ms_cluster_df["Frequency"].max()),
    value = (float(filtered_ms_cluster_df["Frequency"].min()), float(filtered_ms_cluster_df["Frequency"].max())), 
    key = "ms_freq_slider"
)

# Checkbox for Monetary
# filter_monetary = streamlit.checkbox("Filter by Monetary")
# if filter_monetary:
scaled_monetary_range4 = streamlit.slider(
    "Which standardized value of Monetary in sterling are you interested in?",
    min_value = float(filtered_ms_cluster_df["Monetary"].min()),
    max_value = float(filtered_ms_cluster_df["Monetary"].max()),
    value = (float(filtered_ms_cluster_df["Monetary"].min()), float(filtered_ms_cluster_df["Monetary"].max())), 
    key = "ms_monet_slider"
)

# Apply filters dynamically
filtered_df4 = filtered_ms_cluster_df.copy()

# if filter_recency:
filtered_df4 = filtered_df4[
    (filtered_df4["Recency"] >= scaled_recency_range4[0]) &
    (filtered_df4["Recency"] <= scaled_recency_range4[1])
]

# if filter_frequency:
filtered_df4 = filtered_df4[
    (filtered_df4["Frequency"] >= scaled_frequency_range4[0]) &
    (filtered_df4["Frequency"] <= scaled_frequency_range4[1])
]

# if filter_monetary:
filtered_df4 = filtered_df4[
    (filtered_df4["Monetary"] >= scaled_monetary_range4[0]) &
    (filtered_df4["Monetary"] <= scaled_monetary_range4[1])
]

# Display the totals side by side
streamlit.subheader("Average of Recency, Frequency, and Monetary Values of the Mean Shift Cluster(s)")

# Create columns
col1, col2, col3 = streamlit.columns(3)

with col1:
    streamlit.metric("Average of Recency", filtered_df4["Recency"].mean())

with col2:
    streamlit.metric("Average of Frequency", filtered_df4['Frequency'].mean())

with col3:
    streamlit.metric("Average of Monetary", filtered_df4["Monetary"].mean())

ms_fig3d_st = px.scatter_3d(filtered_df4, x = "Recency", y = "Frequency", z = "Monetary", color = filtered_df4["Mean Shift Cluster"], 
                           title = "3D Mean Shift Clusters Visualization", size_max = 30, width = 1000, height = 680, opacity = 1.0)

# ms_fig3d_st.show()

streamlit.plotly_chart(ms_fig3d_st, use_container_width = True)

# create layout with 2 columns
col16, col17 = streamlit.columns(2)

with col16:
    # Monetary Mean by K-Means Cluster Pie Chart
    streamlit.write("Pie Chart of Contribution to Monetary Mean by Mean Shift Cluster")
    # Create a pie chart using Plotly
    ms_monet_mean_pie = go.Figure(data = [go.Pie(
        labels = [f'Cluster {c}' for c in mmmsc_labels],
        values = ms_monet_avg,
        textinfo = 'percent+label',
        textposition = 'inside',
        hoverinfo = 'label+percent+value',
        hole = 0.4,
        marker = dict(line = dict(color = 'white', width = 3))
    )])

    # Update layout to add title
    ms_monet_mean_pie.update_layout(
        legend_title_text = "Mean Shift cluster label",
        legend_font_size = 10,
        legend = dict(orientation = "h", yanchor = "bottom", y = -0.3, xanchor = "center", x = 0.5)
    )

    # Display the pie chart in Streamlit
    streamlit.plotly_chart(ms_monet_mean_pie)

with col17:
    # Monetary Mean by K-Means Cluster Pie Chart
    streamlit.write("Pie Chart of Contribution to Frequency Mean by Mean Shift Cluster")
    # Create a pie chart using Plotly
    ms_freq_mean_pie = go.Figure(data = [go.Pie(
        labels = [f'Cluster {c}' for c in fmmsc_labels],
        values = ms_freq_avg,
        textinfo = 'percent+label',
        textposition = 'inside',
        hoverinfo = 'label+percent+value',
        hole = 0.4,
        marker = dict(line = dict(color = 'white', width = 3))
    )])

    # Update layout to add title
    ms_freq_mean_pie.update_layout(
        legend_title_text = "Mean Shift cluster label",
        legend_font_size = 10,
        legend = dict(orientation = "h", yanchor = "bottom", y = -0.3, xanchor = "center", x = 0.5)
    )

    # Display the pie chart in Streamlit
    streamlit.plotly_chart(ms_freq_mean_pie)

# create layout with 2 columns
col18, col19 = streamlit.columns(2)

with col18:
    # Monetary Mean by K-Means Cluster Pie Chart
    streamlit.write("Pie Chart of Contribution to Total Monetary by Mean Shift Cluster")
    # Create a pie chart using Plotly
    ms_tot_monet_pie = go.Figure(data = [go.Pie(
        labels = [f'Cluster {c}' for c in tmmsc_labels],
        values = total_ms_monet,
        textinfo = 'percent+label',
        textposition = 'inside',
        hoverinfo = 'label+percent+value',
        hole = 0.4,
        marker = dict(line = dict(color = 'white', width = 3))
    )])

    # Update layout to add title
    ms_tot_monet_pie.update_layout(
        legend_title_text = "Mean Shift cluster label",
        legend_font_size = 10,
        legend = dict(orientation = "h", yanchor = "bottom", y = -0.3, xanchor = "center", x = 0.5)
    )

    # Display the pie chart in Streamlit
    streamlit.plotly_chart(ms_tot_monet_pie)

with col19:
    # Monetary Mean by K-Means Cluster Pie Chart
    streamlit.write("Pie Chart of Contribution to Total Frequency by Mean Shift Cluster")
    # Create a pie chart using Plotly
    ms_tot_freq_pie = go.Figure(data = [go.Pie(
        labels = [f'Cluster {c}' for c in tfmsc_labels],
        values = total_ms_freq,
        textinfo = 'percent+label',
        textposition = 'inside',
        hoverinfo = 'label+percent+value',
        hole = 0.4,
        marker = dict(line = dict(color = 'white', width = 3))
    )])

    # Update layout to add title
    ms_tot_freq_pie.update_layout(
        legend_title_text = "Mean Shift cluster label",
        legend_font_size = 10,
        legend = dict(orientation = "h", yanchor = "bottom", y = -0.3, xanchor = "center", x = 0.5)
    )

    # Display the pie chart in Streamlit
    streamlit.plotly_chart(ms_tot_freq_pie)

# streamlit run thesis_clustering_code.py
streamlit.divider()
streamlit.header("Data Source: Online Retail Sales dataset obtained from Kaggle")
OnlineRetailDF
streamlit.write("The dataset consists of ", OnlineRetailDF.shape[0], "online transactions in the UK-based online retail and ", OnlineRetailDF.shape[1], "variables.")
streamlit.divider()
streamlit.header("The 3D dataset with Recency, Frequency, and Monetary variable after feature engineering on the original dataset")
RFM_DF
streamlit.write("After standardized:")
scaled_X_DF
# OnlineRetailDF

# OnlineRetailDF.shape

# OnlineRetailDF.columns

# print("\n\n\n")
